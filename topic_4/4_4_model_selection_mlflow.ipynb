{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separated-repair",
   "metadata": {},
   "source": [
    "# Applied Project in Big Data on Industrial Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-convention",
   "metadata": {},
   "source": [
    "## MODELS SELECTION TECHNIQUES\n",
    "## Part IV. MLflow framework to manage experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbf97b-79d4-4b5d-a66e-202589f2ec00",
   "metadata": {},
   "source": [
    "### 1. Install and start MLflow server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4281bf3b-734b-4d4c-874f-d924947c691e",
   "metadata": {},
   "source": [
    "You can easily install [MLflow](https://mlflow.org/) for your tasks in `DataScience environment` with the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd2a69-3053-4d58-90b8-d94dd5e9c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /home/jovyan/__MANUAL/manutils/start-mlflow.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46089d43-5acf-4dcf-8eae-400de782131f",
   "metadata": {},
   "source": [
    "To run install process open a terminal and type `cd ~ && __MANUAL/manutils/start-mlflow.sh` and MLflow will be installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-immune",
   "metadata": {},
   "source": [
    "### 2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer, \n",
    "    CountVectorizer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    train_test_split,\n",
    "    StratifiedKFold\n",
    ")\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param, log_params, log_artifacts\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "N_CORES = min(\n",
    "    multiprocessing.cpu_count(), \n",
    "    int(float(os.environ['CPU_LIMIT']))\n",
    ")\n",
    "print('cores:', N_CORES)\n",
    "mlflow.set_tracking_uri(f'file:///home/jovyan/{os.environ[\"JUPYTERHUB_USER\"]}_mlflow')\n",
    "print('MLflow UI available at:',\n",
    "      'https://jhas01.gsom.spbu.ru{}proxy/{}/'.format(\n",
    "          os.environ['JUPYTERHUB_SERVICE_PREFIX'], 50000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-shoot",
   "metadata": {},
   "source": [
    "### 2. Create config and place to store artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39adf4d-173c-4bb2-8b64-3cf3b96d9bda",
   "metadata": {},
   "source": [
    "It would be a good idea to store all experiment's artifacts in one place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# here is our config dictionary\n",
    "# we can use it to manage model's parameters\n",
    "# and save it to disk for a history\n",
    "VER = 'v1'\n",
    "CONFIG = {\n",
    "    'version': VER,\n",
    "    'start_time': str(datetime.datetime.fromtimestamp(start_time)),\n",
    "    'sample_size': 1500,\n",
    "    'ngram_range': (1, 1), \n",
    "    'max_df': .95, \n",
    "    'min_df': 5,\n",
    "    'clf': 'GradientBoostingClassifier', # 'RandomForestClassifier' or `GradientBoostingClassifier`\n",
    "    'folds': 4,\n",
    "    'seed': 2023,\n",
    "    'n_iters': 10,\n",
    "    'comments': 'my first model'\n",
    "}\n",
    "\n",
    "# path to store our model\n",
    "# will create folder each time\n",
    "# we run our training code\n",
    "MDLS_PATH = f'./models_{VER}'\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/config.json', 'w') as file:\n",
    "    json.dump(CONFIG, file)\n",
    "\n",
    "# useful trick to fix randomness\n",
    "def seed_all(seed):\n",
    "    \"\"\"\n",
    "    Sometimes it is useful to nail all randomness\n",
    "    and fix all random seeds for reproducibility.\n",
    "    \n",
    "    This function fixes all random seeds for current pipline, \n",
    "    but it could be extended e.g. for Tensorflow library \n",
    "    you may want to add `tf.random.set_seed(seed)` in the code.\n",
    "    \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-virtue",
   "metadata": {},
   "source": [
    "### 2. Dataset for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-willow",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('articles_data.csv')\n",
    "df = df.sample(CONFIG['sample_size']).reset_index()\n",
    "del df['index']\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37ca9d-5006-4dee-91b9-80d332c766aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary but can be helpful\n",
    "# to reproduce experiments\n",
    "save_data_path = f'{MDLS_PATH}/data_{CONFIG[\"version\"]}.csv'\n",
    "df.to_csv(save_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-elements",
   "metadata": {},
   "source": [
    "### 3. Modelling with save of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(data, vectorizer):\n",
    "    print('total texts:', len(data))\n",
    "    features = vectorizer.fit_transform(data)\n",
    "    print(\n",
    "        'features shape:', features.shape, \n",
    "        'max:', np.max(features), \n",
    "        'min:', np.min(features)\n",
    "    )\n",
    "    return features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_model(X, y, \n",
    "                    folds, clf,\n",
    "                    vectorizer, ngram_range=(1, 1), \n",
    "                    max_df=.2, min_df=8, seed=2022):\n",
    "    scores = {}\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "    for fold, (train_idxs, test_idxs) in enumerate(skf.split(X, y)):\n",
    "        \n",
    "        # MLflow run initialization\n",
    "        name_of_run = f'run_model_{CONFIG[\"version\"]}_{datetime.datetime.now()}'\n",
    "        with mlflow.start_run(run_name=name_of_run) as run:\n",
    "            \n",
    "            # train model\n",
    "            X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "            y_train, y_test = y.iloc[train_idxs], y.iloc[test_idxs]\n",
    "            X_train, vectorizer = text_features(\n",
    "                X_train, \n",
    "                vectorizer=vectorizer\n",
    "            )\n",
    "            X_test = vectorizer.transform(X_test)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # saving models\n",
    "            # more about https://scikit-learn.org/stable/model_persistence.html\n",
    "            # NOTE - not only model, but vectorizer too!\n",
    "            file_name = f'{MDLS_PATH}/model_fold_{fold}.joblib'\n",
    "            dump(clf, file_name)\n",
    "            print('saved to', file_name)\n",
    "            file_name = f'{MDLS_PATH}/vectorizer_fold_{fold}.joblib'\n",
    "            dump(vectorizer, file_name)\n",
    "            print('saved to', file_name)\n",
    "\n",
    "            # metrics\n",
    "            y_score = clf.predict_proba(X_test)\n",
    "            roc_auc_score_ = roc_auc_score(y_test, y_score[:, 1])\n",
    "            roc_auc_scores.append(roc_auc_score_)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            f1_score_ = f1_score(y_test, y_pred)\n",
    "            f1_scores.append(f1_score_)\n",
    "            msg = f'fold {fold} - val ROC-AUC score: {roc_auc_score_:.2f}, val f1-score: {f1_score_:.2f}'\n",
    "            print(msg)\n",
    "\n",
    "            scores[f'fold {fold}'] = {\n",
    "                'roc_auc_scores': roc_auc_scores,\n",
    "                'f1_scores': f1_scores\n",
    "            }\n",
    "\n",
    "            # MLflow tracking model\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "            mlflow.sklearn.log_model(\n",
    "                clf, \n",
    "                'model',\n",
    "                registered_model_name=f'model {CONFIG[\"version\"]} {CONFIG[\"clf\"]} fold {fold}', \n",
    "                signature=signature\n",
    "            )\n",
    "            mlflow.log_artifact(\n",
    "                local_path=file_name,\n",
    "                artifact_path='vectorizer',\n",
    "            )\n",
    "\n",
    "            # MLflow tracking config\n",
    "            for key, value in CONFIG.items():\n",
    "                mlflow.log_param(key, value)\n",
    "\n",
    "            # MLflow tracking metrics\n",
    "            mlflow.log_metric('ROC-AUC score', roc_auc_score_)\n",
    "            mlflow.log_metric('f1-score', f1_score_)\n",
    "\n",
    "            # logging (if needed)\n",
    "            # read about logging for production cases here https://docs.python.org/3/library/logging.html\n",
    "            log_file_name = f'{MDLS_PATH}/model_{CONFIG[\"version\"]}.log'\n",
    "            log_string = f'{str(datetime.datetime.fromtimestamp(time.time()))} - {msg}\\n'\n",
    "            with open(log_file_name, 'a') as file:\n",
    "                file.write(log_string)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectorizer with respect to\n",
    "# our configuration parameters\n",
    "vectorizer=TfidfVectorizer(\n",
    "    ngram_range=CONFIG['ngram_range'], \n",
    "    max_df=CONFIG['max_df'], \n",
    "    min_df=CONFIG['min_df']\n",
    ")\n",
    "\n",
    "# select the type of the model\n",
    "if CONFIG['clf'] == 'RandomForestClassifier':\n",
    "    clf = RandomForestClassifier(n_estimators=CONFIG['n_iters']) \n",
    "elif CONFIG['clf'] == 'GradientBoostingClassifier':\n",
    "    clf = GradientBoostingClassifier(n_estimators=CONFIG['n_iters']) \n",
    "else:\n",
    "    clf = LogisticRegression()\n",
    "    \n",
    "# start our training\n",
    "scores = cross_val_model(\n",
    "    X=df['proc'], \n",
    "    y=df['target'], \n",
    "    folds=CONFIG['folds'], \n",
    "    clf=clf,\n",
    "    vectorizer=vectorizer,\n",
    "    seed=CONFIG['seed']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b422cf2-eda4-4b17-919b-cac164b6b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83093830-9ada-41ab-93c8-5f6f9f9cc0ed",
   "metadata": {},
   "source": [
    "### 5. Fetching a model from the MLflow model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449598cb-808a-4642-9a64-5fd6e7b6e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find `run_id` in MLflow interface\n",
    "run_id = 'af4c1f9f717a485eba82aad544c7aecd'\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f'file:///home/jovyan/vgarshin_mlflow/0/{run_id}/artifacts/model/'\n",
    ")\n",
    "vectorizer_path = f'/home/jovyan/vgarshin_mlflow/0/{run_id}/artifacts/vectorizer/'\n",
    "vectorizer_path = vectorizer_path + os.listdir(vectorizer_path)[0]\n",
    "vectorizer = load(vectorizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d17ce3-b1d9-4e86-acd6-f962226ba050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not a good idea to test our models\n",
    "# on the data they were trained on\n",
    "# but it is just a demo of approach\n",
    "df_tmp = pd.read_csv('articles_data.csv')\n",
    "df_tmp = df_tmp.sample(100).reset_index()\n",
    "del df_tmp['index']\n",
    "print(df_tmp.shape)\n",
    "display(df_tmp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe29a0c-771c-4f7e-96d5-8089b7d83519",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vectorizer.transform(df_tmp['proc'])\n",
    "y_score = model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af265e18-35e1-4391-85e5-85142987e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['predictions'] = y_score\n",
    "print(df_tmp.shape)\n",
    "display(df_tmp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247bd7b-cb77-4c94-8367-d399561e58a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(df_tmp.target, df_tmp.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09383a68-ec80-4428-8957-10b14acbbe62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
