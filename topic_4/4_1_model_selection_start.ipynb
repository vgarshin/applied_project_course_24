{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separated-repair",
   "metadata": {},
   "source": [
    "# Applied Project in Big Data on Industrial Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-convention",
   "metadata": {},
   "source": [
    "## MODELS SELECTION TECHNIQUES\n",
    "## Part I. Vanilla pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-immune",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer, \n",
    "    CountVectorizer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_curve, \n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, \n",
    "    train_test_split,\n",
    "    StratifiedKFold\n",
    ")\n",
    "pd.set_option('display.max_columns', None)\n",
    "N_CORES = min(\n",
    "    multiprocessing.cpu_count(), \n",
    "    int(float(os.environ['CPU_LIMIT']))\n",
    ")\n",
    "print('cores:', N_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-virtue",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83d45c-862c-4b25-a5ce-905ca68bff3a",
   "metadata": {},
   "source": [
    "#### 2.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a8f36-4f6b-458f-8df1-e1ea6bd0bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jovyan/apbdid_24/topic_2/articles_data/arcicles_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{data_path}', sep=',', index_col=0)\n",
    "#del df['index']\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d852a-866f-44da-bcdf-8eac5339b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.apply(\n",
    "    lambda row: ' '.join([str(row['title']), str(row['annotation'])]), \n",
    "    axis=1\n",
    ")\n",
    "del df['title'], df['annotation']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fea91-31ee-46f6-adcb-0ce334bd65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr = df.groupby('target').count()\n",
    "df_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a3c45-9364-4231-9b8c-6b777239ba28",
   "metadata": {},
   "source": [
    "#### 2.2. Simplify our task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c42ad-08f4-4696-b336-e36a7794e285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_gr[df_gr.url == 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51558125-bc2a-4a63-806e-5ce0b9a6e950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = df_gr[df_gr.url > 900].index\n",
    "list(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d661a-e22f-457d-8b37-1c2ec0ee64b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['target'] = df['target'].map({v:k for k, v in enumerate(targets[1:3])})\n",
    "df = df[df['target'].notna()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034b18c-63b9-4771-af8a-8e0a77c4f588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25691b39-88fa-433b-973a-c58b8d3a16d7",
   "metadata": {},
   "source": [
    "### 3. Basic NLP preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66961e31-8599-43ba-a1c1-39e7de1ea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2 as pm\n",
    "import nltk\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "LANG = 'russian'\n",
    "MORPH = pm.MorphAnalyzer()\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = nltk.corpus.stopwords.words(LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4394bc51-e3d8-4da6-a57b-c96ca83004cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence, as_list=False):\n",
    "    s = sentence.replace('<b>', '').replace('</b>', '')\n",
    "    s = re.sub('[^а-яА-Яa-zA-Z]+', ' ', s).strip().lower()\n",
    "    s = re.sub('ё', 'е', s)\n",
    "    funсtion_words = {'INTJ', 'PRCL', 'CONJ', 'PREP'}\n",
    "    lemmatized_words = list(map(lambda word: MORPH.parse(word)[0], s.split()))\n",
    "    result = []\n",
    "    for word in lemmatized_words:\n",
    "        if word.tag.POS not in funсtion_words:\n",
    "            result.append(word.normal_form)\n",
    "    result = [w for w in result if w not in STOPWORDS]\n",
    "    if as_list:\n",
    "        return result\n",
    "    else:\n",
    "        return ' '.join(result)\n",
    "    \n",
    "def apply_parallel(texts, func, n_cores=2):\n",
    "    pool = Pool(n_cores)\n",
    "    split = np.array_split(texts, n_cores)\n",
    "    res = [item for sub in pool.map(func, split) for item in sub]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return res\n",
    "\n",
    "def preprocessing_list(sentences):\n",
    "    return [preprocessing(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148ca5f-687c-4995-9085-befd96235167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "proc = apply_parallel(\n",
    "    df.text, \n",
    "    preprocessing_list, \n",
    "    n_cores=N_CORES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b48950-b501-4fd9-88d1-59e54d9d37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'proc'] = proc\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e175f-f962-4092-8a64-837483ed7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['target', 'proc']].to_csv('articles_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df299d2-6ee8-4b1a-a9a4-ac14def1a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('articles_data.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-elements",
   "metadata": {},
   "source": [
    "### 3. Just make a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DF = .95\n",
    "MIN_DF = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(data, vectorizer):\n",
    "    print('total texts:', len(data))\n",
    "    features = vectorizer.fit_transform(data)\n",
    "    print(\n",
    "        'features shape:', features.shape, \n",
    "        'max:', np.max(features), \n",
    "        'min:', np.min(features)\n",
    "    )\n",
    "    return features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer=TfidfVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    max_df=MAX_DF, \n",
    "    min_df=MIN_DF\n",
    ")\n",
    "features, vectorizer = text_features(\n",
    "    df['proc'], \n",
    "    vectorizer=vectorizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215725c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['proc'], \n",
    "    df['target'], \n",
    "    test_size=.3, \n",
    "    random_state=2022\n",
    ")\n",
    "X_train, vectorizer = text_features(\n",
    "    X_train, \n",
    "    vectorizer=vectorizer\n",
    ")\n",
    "X_test = vectorizer.transform(X_test)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c57c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87702a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17addc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-click",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_score = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5dd0f-d9b4-4aca-a2f7-ef48e6780f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_score[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8fb59-e2e8-43b4-bd86-a198b86c1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for th in range(1, 10):\n",
    "    print(\n",
    "        'threshold = ', th / 10,\n",
    "        '| ROC AUC score = ', roc_auc_score(\n",
    "            y_test, \n",
    "            [1 if x > (th / 10) else 0 for x in y_score[:, 1]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn Example of Receiver Operating Characteristic (ROC) \n",
    "# metric to evaluate classifier output quality.\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color='darkorange',\n",
    "    lw=lw,\n",
    "    label='ROC curve (area = %0.2f)' % roc_auc,\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, recall, _ = precision_recall_curve(\n",
    "    y_test,\n",
    "    y_score[:, 1], \n",
    "    pos_label=clf.classes_[1]\n",
    ")\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-aquarium",
   "metadata": {},
   "source": [
    "### 4. More advanced model approach: cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_model(X, y, \n",
    "                    folds, clf,\n",
    "                    vectorizer, ngram_range=(1, 1), \n",
    "                    max_df=.2, min_df=8, seed=2022):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=folds, random_state=seed, shuffle=True)\n",
    "    for fold, (train_idxs, test_idxs) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idxs], X.iloc[test_idxs]\n",
    "        y_train, y_test = y.iloc[train_idxs], y.iloc[test_idxs]\n",
    "        X_train, vectorizer = text_features(\n",
    "            X_train, \n",
    "            vectorizer=vectorizer\n",
    "        )\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_score = clf.predict_proba(X_test)\n",
    "        scores_fold = roc_auc_score(y_test, y_score[:, 1])\n",
    "        print(f'fold {fold} val score: {scores_fold:.2f}')\n",
    "        scores.append(scores_fold)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(\n",
    "    ngram_range=(1, 1), \n",
    "    max_df=MAX_DF, \n",
    "    min_df=MIN_DF\n",
    ")\n",
    "cross_val_model(\n",
    "    X=df['proc'], \n",
    "    y=df['target'], \n",
    "    folds=5, \n",
    "    clf=LogisticRegression(),\n",
    "    vectorizer=vectorizer,\n",
    "    seed=2022\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab00f0d-45fe-4c61-95af-e3a8b837f6e2",
   "metadata": {},
   "source": [
    "Let's explore the options how to manage your experiments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed861d04-880e-436d-901c-3c12fe865979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
