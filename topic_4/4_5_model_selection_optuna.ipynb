{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d69e194",
   "metadata": {},
   "source": [
    "# Applied Project in Big Data on Industrial Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f087f",
   "metadata": {},
   "source": [
    "## MODELS SELECTION TECHNIQUES\n",
    "## Part V. Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308fbc2",
   "metadata": {},
   "source": [
    "### 1. Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c4996-1982-495a-980d-dc7f0a518eb2",
   "metadata": {},
   "source": [
    "[Optuna](https://optuna.org/) is an open source hyperparameter optimization framework to automate hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24deff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install optuna\n",
    "!pip install lightgbm==3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe392c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold\n",
    ")\n",
    "from sklearn.feature_extraction.text import (\n",
    "    TfidfVectorizer, \n",
    "    CountVectorizer\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "pd.set_option('display.max_columns', None)\n",
    "N_CORES = min(\n",
    "    multiprocessing.cpu_count(), \n",
    "    int(float(os.environ['CPU_LIMIT']))\n",
    ")\n",
    "print('cores:', N_CORES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-drove",
   "metadata": {},
   "source": [
    "### 2. Create config and place to store artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb2704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 'lgb_v0'\n",
    "CONFIG = {\n",
    "    'version': VER,\n",
    "    'sample_size': 1500,\n",
    "    'ngram_range': (1, 1),\n",
    "    'folds': 4,\n",
    "    'iters': 50,\n",
    "    'patience': 5,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 2022,\n",
    "    'lr': .01,\n",
    "    'max_trials': 10,\n",
    "    'comments': ''\n",
    "}\n",
    "MDLS_PATH = f'./models_{VER}'\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/config.json', 'w') as file:\n",
    "    json.dump(CONFIG, file)\n",
    "    \n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(CONFIG['seed'])\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-thriller",
   "metadata": {},
   "source": [
    "### 3. Dataset for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921169e-c860-4689-8651-0de87c22f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('articles_data.csv')\n",
    "df = df.sample(CONFIG['sample_size']).reset_index()\n",
    "del df['index']\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906180f-c246-4519-8bbe-c7fd1c12db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5068515-94c1-47e1-852d-a33588ace2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary but can be helpful\n",
    "# to reproduce experiments\n",
    "save_data_path = f'{MDLS_PATH}/data_{CONFIG[\"version\"]}.csv'\n",
    "df.to_csv(save_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-wales",
   "metadata": {},
   "source": [
    "### 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-truck",
   "metadata": {},
   "source": [
    "#### 4.1. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features(data, vectorizer):\n",
    "    print('total texts:', len(data))\n",
    "    features = vectorizer.fit_transform(data)\n",
    "    print(\n",
    "        'features shape:', features.shape, \n",
    "        'max:', np.max(features), \n",
    "        'min:', np.min(features)\n",
    "    )\n",
    "    return features, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-dress",
   "metadata": {},
   "source": [
    "#### 4.2. Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    # parameters intervals to search within\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', .01, .5),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', .4, 1),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', .4, 1),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'seed': CONFIG['seed'],\n",
    "        'n_jobs': CONFIG['n_jobs'],\n",
    "        'verbose': 1\n",
    "    }\n",
    "    \n",
    "    # vectorizer is also based on search parameters\n",
    "    vectorizer=TfidfVectorizer(\n",
    "        ngram_range=CONFIG['ngram_range'], \n",
    "        max_df=trial.suggest_uniform('max_df', .5, 1), \n",
    "        min_df=trial.suggest_int('min_df', 1, 10)\n",
    "    )\n",
    "    \n",
    "    # split dataset for train-validation\n",
    "    oof_predictions = np.zeros(df.shape[0])\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=CONFIG['folds'], \n",
    "        random_state=CONFIG['seed'], \n",
    "        shuffle=True\n",
    "    ).split(df, df['target'])\n",
    "    \n",
    "    # train loop\n",
    "    for fold, (train_idxs, val_idxs) in enumerate(kfold):\n",
    "        print(f'========== FOLD: {fold} ==========')\n",
    "        X_train, X_val = df['proc'].iloc[train_idxs], df['proc'].iloc[val_idxs]\n",
    "        y_train, y_val = df['target'].iloc[train_idxs], df['target'].iloc[val_idxs]\n",
    "        X_train, vectorizer = text_features(\n",
    "            X_train, \n",
    "            vectorizer=vectorizer\n",
    "        )\n",
    "        X_val = vectorizer.transform(X_val)\n",
    "        train_dataset = lgb.Dataset(X_train, y_train)\n",
    "        val_dataset = lgb.Dataset(X_val, y_val)\n",
    "        \n",
    "        # LGBM regression\n",
    "        model = lgb.train(params=params,\n",
    "                          num_boost_round=CONFIG['iters'],\n",
    "                          train_set=train_dataset, \n",
    "                          valid_sets=[train_dataset, val_dataset], \n",
    "                          verbose_eval=int(CONFIG['iters'] / 5),\n",
    "                          early_stopping_rounds=CONFIG['patience'])\n",
    "        \n",
    "        # OOF test for vaidation\n",
    "        oof_predictions[val_idxs] = model.predict(X_val)\n",
    "    \n",
    "    # metrics\n",
    "    roc_auc_score_ = roc_auc_score(df['target'], oof_predictions)\n",
    "    f1_score_ = f1_score(df['target'], [1 if x > .5 else 0 for x in oof_predictions])\n",
    "    print(\n",
    "        '*' * 50 + '\\n',\n",
    "        f'OOF (out-of-fold) ROC AUC score: {roc_auc_score_}\\n',\n",
    "        f'OOF (out-of-fold) f1 score: {f1_score_}\\n\\n\\n'\n",
    "    )\n",
    "    return roc_auc_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-signature",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna init and run\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=CONFIG['max_trials'])\n",
    "\n",
    "# save best parameters\n",
    "\n",
    "params = study.best_params\n",
    "print('optuna search best params:', params)\n",
    "with open(f'{MDLS_PATH}/lgb_params.json', 'w') as file:\n",
    "    json.dump(params, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6e47a-a636-4c31-90ee-3810675b581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best target ROC AUC achieved:', study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54640b75-c90f-4f16-8ba4-2876769e22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best parameters:', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-testament",
   "metadata": {},
   "source": [
    "#### 4.3. Train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lgb(train, params):\n",
    "    vectorizer=TfidfVectorizer(\n",
    "        ngram_range=CONFIG['ngram_range'], \n",
    "        max_df=params['max_df'], \n",
    "        min_df=params['min_df']\n",
    "    )\n",
    "    oof_predictions = np.zeros(df.shape[0])\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=CONFIG['folds'], \n",
    "        random_state=CONFIG['seed'], \n",
    "        shuffle=True\n",
    "    ).split(df, df['target'])\n",
    "    \n",
    "    # train loop\n",
    "    for fold, (train_idxs, val_idxs) in enumerate(kfold):\n",
    "        print(f'========== FOLD: {fold} ==========')\n",
    "        X_train, X_val = df['proc'].iloc[train_idxs], df['proc'].iloc[val_idxs]\n",
    "        y_train, y_val = df['target'].iloc[train_idxs], df['target'].iloc[val_idxs]\n",
    "        X_train, vectorizer = text_features(\n",
    "            X_train, \n",
    "            vectorizer=vectorizer\n",
    "        )\n",
    "        X_val = vectorizer.transform(X_val)\n",
    "        train_dataset = lgb.Dataset(X_train, y_train)\n",
    "        val_dataset = lgb.Dataset(X_val, y_val)\n",
    "        \n",
    "        # LGBM regression with save\n",
    "        model = lgb.train(params=params,\n",
    "                          num_boost_round=CONFIG['iters'],\n",
    "                          train_set=train_dataset, \n",
    "                          valid_sets=[train_dataset, val_dataset], \n",
    "                          verbose_eval=int(CONFIG['iters'] / 5),\n",
    "                          early_stopping_rounds=CONFIG['patience'])\n",
    "        model.save_model(f'{MDLS_PATH}/model_lgb_fold{fold}.lgbm', \n",
    "                         num_iteration=model.best_iteration)\n",
    "        \n",
    "        # OOF test for vaidation\n",
    "        oof_predictions[val_idxs] = model.predict(X_val)\n",
    "    \n",
    "    # metrics ans plot\n",
    "    lgb.plot_importance(model, max_num_features=10)\n",
    "    roc_auc_score_ = roc_auc_score(df['target'], oof_predictions)\n",
    "    f1_score_ = f1_score(df['target'], [1 if x > .5 else 0 for x in oof_predictions])\n",
    "    print(\n",
    "        '*' * 50 + '\\n',\n",
    "        f'OOF (out-of-fold) ROC AUC score: {roc_auc_score_}\\n',\n",
    "        f'OOF (out-of-fold) f1 score: {f1_score_}\\n\\n\\n'\n",
    "    )\n",
    "    return roc_auc_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_PATH}/lgb_params.json', 'r') as file:\n",
    "    params = json.load(file)\n",
    "print('lgb params loaded:', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-stability",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_and_evaluate_lgb(df, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9106a367-2e28-4853-ad55-6449a9297cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
